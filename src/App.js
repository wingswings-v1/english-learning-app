import React, { useState, useEffect, useRef } from 'react';
import * as tf from '@tensorflow/tfjs';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import WordDetail from './components/WordDetail';
import Vocabulary from './components/Vocabulary';

function App() {
  const [model, setModel] = useState(null);
  const [isDetecting, setIsDetecting] = useState(false);
  const [isRealTimeDetection, setIsRealTimeDetection] = useState(false);
  const [predictions, setPredictions] = useState([]);
  const [selectedWord, setSelectedWord] = useState(null);
  const [status, setStatus] = useState('ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•˜ë ¤ë©´ "Start Camera" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.');
  const [vocabulary, setVocabulary] = useState([]);
  const [isBackCamera, setIsBackCamera] = useState(true); // í›„ë©´ ì¹´ë©”ë¼ ìƒíƒœ

  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const detectionIntervalRef = useRef(null);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ëª¨ë¸ ë¡œë“œ ë° ë‹¨ì–´ì¥ ë¡œë“œ
  useEffect(() => {
    loadModel();
    loadVocabulary();
  }, []);

  // ëª¨ë¸ ë¡œë“œ (ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë³µì›)
  const loadModel = async () => {
    try {
      setStatus('AI ëª¨ë¸ì„ ë¡œë”© ì¤‘...');
      console.log('TensorFlow.js ë°±ì—”ë“œ:', tf.getBackend());
      
      // ê°€ì¥ ê¸°ë³¸ì ì¸ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ
      const loadedModel = await cocoSsd.load();
      
      setModel(loadedModel);
      setStatus('AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!');
      console.log('COCO-SSD ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      
    } catch (error) {
      console.error('ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      setStatus(`ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ${error.message}. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.`);
    }
  };

  // ë‹¨ì–´ì¥ ë¡œë“œ
  const loadVocabulary = () => {
    const saved = localStorage.getItem('english-vocabulary');
    if (saved) {
      setVocabulary(JSON.parse(saved));
    }
  };

  // ë‹¨ì–´ì¥ ì €ì¥
  const saveVocabulary = (newVocabulary) => {
    setVocabulary(newVocabulary);
    localStorage.setItem('english-vocabulary', JSON.stringify(newVocabulary));
  };

  // ì¹´ë©”ë¼ ì‹œì‘ (í›„ë©´ ì¹´ë©”ë¼ ìš°ì„ )
  const startCamera = async () => {
    try {
      const facingMode = isBackCamera ? 'environment' : 'user';
      const cameraType = isBackCamera ? 'í›„ë©´' : 'ì „ë©´';
      
      let stream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: { ideal: facingMode }
          } 
        });
        setStatus(`${cameraType} ì¹´ë©”ë¼ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ê°ì§€ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ "Capture & Detect" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.`);
      } catch (primaryCameraError) {
        console.log(`${cameraType} ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨, ë°˜ëŒ€ ì¹´ë©”ë¼ë¡œ ì‹œë„:`, primaryCameraError);
        
        // ë°˜ëŒ€ ì¹´ë©”ë¼ë¡œ í´ë°±
        const fallbackFacingMode = isBackCamera ? 'user' : 'environment';
        const fallbackCameraType = isBackCamera ? 'ì „ë©´' : 'í›„ë©´';
        
        stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: { ideal: fallbackFacingMode }
          } 
        });
        setStatus(`${fallbackCameraType} ì¹´ë©”ë¼ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ê°ì§€ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ "Capture & Detect" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.`);
        
        // í´ë°± ì‹œ ì¹´ë©”ë¼ ìƒíƒœ ì—…ë°ì´íŠ¸
        setIsBackCamera(!isBackCamera);
      }
      
      videoRef.current.srcObject = stream;
      videoRef.current.onloadedmetadata = () => {
        videoRef.current.play();
        const canvas = canvasRef.current;
        const video = videoRef.current;
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      };

    } catch (error) {
      console.error('ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      setStatus('ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  // ì¹´ë©”ë¼ ì „í™˜
  const switchCamera = async () => {
    if (!videoRef.current?.srcObject) {
      setStatus('ë¨¼ì € ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.');
      return;
    }

    try {
      // í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
      const currentStream = videoRef.current.srcObject;
      const tracks = currentStream.getTracks();
      tracks.forEach(track => track.stop());

      // ì¹´ë©”ë¼ ë°©í–¥ ì „í™˜
      setIsBackCamera(!isBackCamera);
      
      // ìƒˆë¡œìš´ ì¹´ë©”ë¼ë¡œ ì¬ì‹œì‘
      await startCamera();
    } catch (error) {
      console.error('ì¹´ë©”ë¼ ì „í™˜ ì‹¤íŒ¨:', error);
      setStatus('ì¹´ë©”ë¼ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  // ì¹´ë©”ë¼ ì¤‘ì§€
  const stopCamera = () => {
    const stream = videoRef.current?.srcObject;
    if (stream) {
      const tracks = stream.getTracks();
      tracks.forEach(track => track.stop());
      videoRef.current.srcObject = null;
    }

    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
    setIsRealTimeDetection(false);
    setStatus('ì¹´ë©”ë¼ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.');
    
    // ìº”ë²„ìŠ¤ì™€ ê²°ê³¼ ì´ˆê¸°í™”
    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    if (ctx) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }
    setPredictions([]);
  };

  // ê°ì²´ ê°ì§€ (ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë³µì›)
  const detectObjects = async (imageElement) => {
    if (!model) {
      setStatus('ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }

    if (isDetecting) {
      return; // ì´ë¯¸ ê°ì§€ ì¤‘ì´ë©´ ìŠ¤í‚µ
    }

    try {
      setIsDetecting(true);
      setStatus('ê°ì²´ë¥¼ ê°ì§€í•˜ëŠ” ì¤‘...');
      
      console.log('ê°ì²´ ê°ì§€ ì‹œì‘...');
      console.log('ì´ë¯¸ì§€ ìš”ì†Œ:', imageElement);
      console.log('ì´ë¯¸ì§€ í¬ê¸°:', imageElement?.videoWidth, 'x', imageElement?.videoHeight);
      
      // ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ê°ì§€ ì‹¤í–‰
      const predictions = await model.detect(imageElement);
      console.log('ì˜ˆì¸¡ ê²°ê³¼:', predictions);
      
      setPredictions(predictions);
      
      // ìº”ë²„ìŠ¤ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
      drawBoundingBoxes(predictions);
      
      setStatus(`${predictions.length}ê°œì˜ ê°ì²´ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.`);
    } catch (error) {
      console.error('ê°ì²´ ê°ì§€ ì‹¤íŒ¨:', error);
      setStatus(`ê°ì²´ ê°ì§€ ì‹¤íŒ¨: ${error.message}`);
    } finally {
      setIsDetecting(false);
    }
  };



  // ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ê¸°ë³¸ ì„¤ì •)
  const drawBoundingBoxes = (predictions) => {
    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    if (!ctx) return;

    // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    predictions.forEach((prediction, index) => {
      const [x, y, width, height] = prediction.bbox;
      const confidence = Math.round(prediction.score * 100);
      
      // ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
      ctx.strokeStyle = '#00ff00';
      ctx.lineWidth = 3;
      ctx.strokeRect(x, y, width, height);
      
      // ë¼ë²¨ ê·¸ë¦¬ê¸°
      ctx.fillStyle = '#00ff00';
      ctx.font = '16px Arial';
      ctx.fillText(`${prediction.class} (${confidence}%)`, x, y - 10);
      
      // í´ë¦­ ê°€ëŠ¥í•œ ì˜ì—­ í‘œì‹œë¥¼ ìœ„í•œ ì‚¬ê°í˜•
      ctx.strokeStyle = 'rgba(0, 255, 0, 0.3)';
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y - 25, ctx.measureText(`${prediction.class} (${confidence}%)`).width, 20);
    });
  };

  // ì‹ ë¢°ë„ì— ë”°ë¥¸ CSS í´ë˜ìŠ¤ ë°˜í™˜
  const getConfidenceClass = (score) => {
    if (score >= 0.8) return 'high';
    if (score >= 0.6) return 'medium';
    if (score >= 0.4) return 'low';
    return 'very-low';
  };

  // ì‹¤ì‹œê°„ ê°ì§€ í† ê¸€ (ê¸°ë³¸ ì„¤ì •)
  const toggleRealTimeDetection = () => {
    if (!isRealTimeDetection) {
      setIsRealTimeDetection(true);
      setStatus('ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.');
      
      // 1ì´ˆë§ˆë‹¤ ê°ì²´ ê°ì§€
      detectionIntervalRef.current = setInterval(() => {
        if (videoRef.current?.readyState === videoRef.current?.HAVE_ENOUGH_DATA) {
          // ì´ì „ ê°ì§€ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìŠ¤í‚µ
          if (!isDetecting) {
            detectObjects(videoRef.current);
          }
        }
      }, 1000);
    } else {
      setIsRealTimeDetection(false);
      setStatus('ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.');
      
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
        detectionIntervalRef.current = null;
      }
      
      // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
      const canvas = canvasRef.current;
      const ctx = canvas?.getContext('2d');
      if (ctx) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
      setPredictions([]);
    }
  };

  // ë‹¨ì–´ ì„ íƒ
  const handleWordSelect = (word) => {
    setSelectedWord(word);
  };

  // ë‹¨ì–´ì¥ì— ì¶”ê°€
  const addToVocabulary = (word) => {
    if (!vocabulary.find(item => item.word === word)) {
      const newItem = {
        word,
        addedAt: new Date().toISOString(),
        id: Date.now()
      };
      saveVocabulary([...vocabulary, newItem]);
    }
  };

  // ë‹¨ì–´ì¥ì—ì„œ ì œê±°
  const removeFromVocabulary = (id) => {
    const newVocabulary = vocabulary.filter(item => item.id !== id);
    saveVocabulary(newVocabulary);
  };

  // ìº”ë²„ìŠ¤ í´ë¦­ ì´ë²¤íŠ¸
  const handleCanvasClick = (event) => {
    if (predictions.length === 0) return;
    
    const canvas = canvasRef.current;
    const rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const y = event.clientY - rect.top;
    
    // í´ë¦­ëœ ê°ì²´ ì°¾ê¸°
    predictions.forEach(prediction => {
      const [bx, by, bwidth, bheight] = prediction.bbox;
      const labelHeight = 25;
      const labelY = by - labelHeight;
      
      // ë¼ë²¨ ì˜ì—­ í´ë¦­ í™•ì¸
      if (x >= bx && x <= bx + bwidth && y >= labelY && y <= by) {
        handleWordSelect(prediction.class);
      }
    });
  };

  return (
    <div className="container">
      <h1 className="header">ğŸ¯ English Learning with AI</h1>
      
      <div className="video-container">
        <video ref={videoRef} id="video" autoPlay muted playsInline></video>
        <canvas 
          ref={canvasRef} 
          id="canvas"
          onClick={handleCanvasClick}
          style={{ pointerEvents: 'auto' }}
        ></canvas>
      </div>

      <div className="controls">
        <button onClick={startCamera}>ğŸ“¹ Start Camera</button>
        <button 
          onClick={switchCamera}
          disabled={!videoRef.current?.srcObject}
          style={{
            background: 'linear-gradient(45deg, #9b59b6, #8e44ad)',
            opacity: videoRef.current?.srcObject ? 1 : 0.5
          }}
        >
          {isBackCamera ? 'ğŸ”„ ì „ë©´ ì¹´ë©”ë¼ë¡œ ì „í™˜' : 'ğŸ”„ í›„ë©´ ì¹´ë©”ë¼ë¡œ ì „í™˜'}
        </button>
        <button 
          onClick={toggleRealTimeDetection}
          style={{
            background: isRealTimeDetection 
              ? 'linear-gradient(45deg, #ff6b6b, #ee5a24)' 
              : 'linear-gradient(45deg, #667eea, #764ba2)'
          }}
        >
          {isRealTimeDetection ? 'ğŸŸ¢ Stop Real-time Detection' : 'ğŸ”´ Start Real-time Detection'}
        </button>
        <button onClick={() => detectObjects(videoRef.current)}>ğŸ“¸ Capture & Detect</button>
        <button onClick={stopCamera}>â¹ï¸ Stop Camera</button>
      </div>

      <div className="status">{status}</div>
      
      {/* ë””ë²„ê¹… ì •ë³´ */}
      <div style={{ 
        background: '#f0f0f0', 
        padding: '10px', 
        margin: '10px 0', 
        borderRadius: '5px',
        fontSize: '12px',
        fontFamily: 'monospace'
      }}>
        <strong>ë””ë²„ê¹… ì •ë³´:</strong><br/>
        User Agent: {navigator.userAgent}<br/>
        TensorFlow ë°±ì—”ë“œ: {tf.getBackend()}<br/>
        ëª¨ë¸ ìƒíƒœ: {model ? 'ë¡œë“œë¨' : 'ë¡œë“œ ì•ˆë¨'}<br/>
        ê°ì§€ ì¤‘: {isDetecting ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}<br/>
        ì‹¤ì‹œê°„ ê°ì§€: {isRealTimeDetection ? 'í™œì„±' : 'ë¹„í™œì„±'}<br/>
        ì˜ˆì¸¡ ê²°ê³¼: {predictions.length}ê°œ<br/>
        ë¹„ë””ì˜¤ ìƒíƒœ: {videoRef.current?.readyState || 'ì—†ìŒ'}
      </div>

      <div className="detection-results">
        <h3>ğŸ” Detected Objects:</h3>
        {predictions.length === 0 ? (
          <div className="detection-item">ê°ì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.</div>
        ) : (
          predictions.map((prediction, index) => {
            const confidence = Math.round(prediction.score * 100);
            const confidenceClass = getConfidenceClass(prediction.score);
            
            return (
              <div key={index} className="detection-item">
                <span 
                  className="object-name" 
                  onClick={() => handleWordSelect(prediction.class)}
                >
                  {prediction.class}
                </span>
                <div>
                  <span className={`confidence ${confidenceClass}`}>
                    {confidence}%
                  </span>
                  <button 
                    className="save-button"
                    onClick={() => addToVocabulary(prediction.class)}
                    disabled={vocabulary.find(item => item.word === prediction.class)}
                  >
                    {vocabulary.find(item => item.word === prediction.class) ? 'âœ“ ì €ì¥ë¨' : 'ğŸ’¾ ì €ì¥'}
                  </button>
                </div>
              </div>
            );
          })
        )}
      </div>

      {selectedWord && (
        <WordDetail 
          word={selectedWord} 
          onClose={() => setSelectedWord(null)}
          onSave={() => addToVocabulary(selectedWord)}
          isSaved={vocabulary.find(item => item.word === selectedWord)}
        />
      )}

      <Vocabulary 
        vocabulary={vocabulary}
        onRemove={removeFromVocabulary}
        onWordSelect={handleWordSelect}
      />
    </div>
  );
}

export default App;