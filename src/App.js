import React, { useState, useEffect, useRef } from 'react';
import * as tf from '@tensorflow/tfjs';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import WordDetail from './components/WordDetail';
import Vocabulary from './components/Vocabulary';

function App() {
  const [model, setModel] = useState(null);
  const [isDetecting, setIsDetecting] = useState(false);
  const [isRealTimeDetection, setIsRealTimeDetection] = useState(false);
  const [predictions, setPredictions] = useState([]);
  const [selectedWord, setSelectedWord] = useState(null);
  const [status, setStatus] = useState('ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•˜ë ¤ë©´ "Start Camera" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.');
  const [vocabulary, setVocabulary] = useState([]);
  const [isBackCamera, setIsBackCamera] = useState(true); // í›„ë©´ ì¹´ë©”ë¼ ìƒíƒœ
  const [detectionMode, setDetectionMode] = useState('normal'); // normal, enhanced

  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const detectionIntervalRef = useRef(null);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ëª¨ë¸ ë¡œë“œ ë° ë‹¨ì–´ì¥ ë¡œë“œ
  useEffect(() => {
    loadModel();
    loadVocabulary();
  }, []);

  // ëª¨ë¸ ë¡œë“œ (í–¥ìƒëœ ëª¨ë¸ ì‚¬ìš©)
  const loadModel = async () => {
    try {
      setStatus('AI ëª¨ë¸ì„ ë¡œë”© ì¤‘...');
      console.log('TensorFlow.js ë°±ì—”ë“œ:', tf.getBackend());
      
      // ë” ì •í™•í•œ ëª¨ë¸ ë¡œë“œ ì‹œë„
      let loadedModel;
      try {
        // MobileNet v2 ê¸°ë°˜ ëª¨ë¸ ì‹œë„ (ë” ì •í™•í•¨)
        loadedModel = await cocoSsd.load({
          base: 'mobilenet_v2'
        });
        setStatus('ê³ ì •ë°€ AI ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!');
        console.log('MobileNet v2 ê¸°ë°˜ COCO-SSD ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      } catch (v2Error) {
        console.log('v2 ëª¨ë¸ ì‹¤íŒ¨, v1ìœ¼ë¡œ í´ë°±:', v2Error);
        // í´ë°±ìœ¼ë¡œ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
        loadedModel = await cocoSsd.load();
        setStatus('ê¸°ë³¸ AI ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
        console.log('ê¸°ë³¸ COCO-SSD ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.');
      }
      
      setModel(loadedModel);
      
      // ì¸ì‹ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª©ë¡ í‘œì‹œ
      displayAvailableClasses();
      
    } catch (error) {
      console.error('ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      setStatus(`ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ${error.message}. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.`);
    }
  };

  // ì¸ì‹ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª©ë¡ í‘œì‹œ
  const displayAvailableClasses = () => {
    const cocoClasses = [
      'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
      'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
      'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
      'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
      'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
      'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
      'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
      'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
      'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
      'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
    ];
    
    console.log('COCO-SSD ì¸ì‹ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ë“¤:', cocoClasses);
    console.log('ì´', cocoClasses.length, 'ê°œ í´ë˜ìŠ¤');
  };

  // ë‹¨ì–´ì¥ ë¡œë“œ
  const loadVocabulary = () => {
    const saved = localStorage.getItem('english-vocabulary');
    if (saved) {
      setVocabulary(JSON.parse(saved));
    }
  };

  // ë‹¨ì–´ì¥ ì €ì¥
  const saveVocabulary = (newVocabulary) => {
    setVocabulary(newVocabulary);
    localStorage.setItem('english-vocabulary', JSON.stringify(newVocabulary));
  };

  // ì¹´ë©”ë¼ ì‹œì‘ (í›„ë©´ ì¹´ë©”ë¼ ìš°ì„ )
  const startCamera = async () => {
    try {
      const facingMode = isBackCamera ? 'environment' : 'user';
      const cameraType = isBackCamera ? 'í›„ë©´' : 'ì „ë©´';
      
      let stream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: { ideal: facingMode }
          } 
        });
        setStatus(`${cameraType} ì¹´ë©”ë¼ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ê°ì§€ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ "Capture & Detect" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.`);
      } catch (primaryCameraError) {
        console.log(`${cameraType} ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨, ë°˜ëŒ€ ì¹´ë©”ë¼ë¡œ ì‹œë„:`, primaryCameraError);
        
        // ë°˜ëŒ€ ì¹´ë©”ë¼ë¡œ í´ë°±
        const fallbackFacingMode = isBackCamera ? 'user' : 'environment';
        const fallbackCameraType = isBackCamera ? 'ì „ë©´' : 'í›„ë©´';
        
        stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: 640 },
            height: { ideal: 480 },
            facingMode: { ideal: fallbackFacingMode }
          } 
        });
        setStatus(`${fallbackCameraType} ì¹´ë©”ë¼ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ê°ì§€ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ "Capture & Detect" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.`);
        
        // í´ë°± ì‹œ ì¹´ë©”ë¼ ìƒíƒœ ì—…ë°ì´íŠ¸
        setIsBackCamera(!isBackCamera);
      }
      
      videoRef.current.srcObject = stream;
      videoRef.current.onloadedmetadata = () => {
        videoRef.current.play();
        const canvas = canvasRef.current;
        const video = videoRef.current;
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      };

    } catch (error) {
      console.error('ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      setStatus('ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  // ì¹´ë©”ë¼ ì „í™˜
  const switchCamera = async () => {
    if (!videoRef.current?.srcObject) {
      setStatus('ë¨¼ì € ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.');
      return;
    }

    try {
      // í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
      const currentStream = videoRef.current.srcObject;
      const tracks = currentStream.getTracks();
      tracks.forEach(track => track.stop());

      // ì¹´ë©”ë¼ ë°©í–¥ ì „í™˜
      setIsBackCamera(!isBackCamera);
      
      // ìƒˆë¡œìš´ ì¹´ë©”ë¼ë¡œ ì¬ì‹œì‘
      await startCamera();
    } catch (error) {
      console.error('ì¹´ë©”ë¼ ì „í™˜ ì‹¤íŒ¨:', error);
      setStatus('ì¹´ë©”ë¼ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  // ì¹´ë©”ë¼ ì¤‘ì§€
  const stopCamera = () => {
    const stream = videoRef.current?.srcObject;
    if (stream) {
      const tracks = stream.getTracks();
      tracks.forEach(track => track.stop());
      videoRef.current.srcObject = null;
    }

    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
    setIsRealTimeDetection(false);
    setStatus('ì¹´ë©”ë¼ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.');
    
    // ìº”ë²„ìŠ¤ì™€ ê²°ê³¼ ì´ˆê¸°í™”
    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    if (ctx) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }
    setPredictions([]);
  };

  // ê°ì²´ ê°ì§€ (í–¥ìƒëœ ì¸ì‹)
  const detectObjects = async (imageElement) => {
    if (!model) {
      setStatus('ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }

    if (isDetecting) {
      return; // ì´ë¯¸ ê°ì§€ ì¤‘ì´ë©´ ìŠ¤í‚µ
    }

    try {
      setIsDetecting(true);
      setStatus('ê°ì²´ë¥¼ ê°ì§€í•˜ëŠ” ì¤‘...');
      
      console.log('ê°ì²´ ê°ì§€ ì‹œì‘...');
      console.log('ì´ë¯¸ì§€ í¬ê¸°:', imageElement?.videoWidth, 'x', imageElement?.videoHeight);
      
      // ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
      const processedImage = preprocessImageForDetection(imageElement);
      
      // ê°ì§€ ëª¨ë“œì— ë”°ë¥¸ ì„¤ì •
      const detectionConfig = detectionMode === 'enhanced' ? {
        maxDetections: 20,        // í–¥ìƒ ëª¨ë“œ: ë” ë§ì€ ê°ì§€
        scoreThreshold: 0.25,     // í–¥ìƒ ëª¨ë“œ: ë” ë‚®ì€ ì„ê³„ê°’
        nmsRadius: 0.3,           // í–¥ìƒ ëª¨ë“œ: ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±°
        numClasses: 80
      } : {
        maxDetections: 10,        // ì¼ë°˜ ëª¨ë“œ: ê¸°ë³¸ ê°ì§€
        scoreThreshold: 0.4,      // ì¼ë°˜ ëª¨ë“œ: ê¸°ë³¸ ì„ê³„ê°’
        nmsRadius: 0.4,           // ì¼ë°˜ ëª¨ë“œ: ê¸°ë³¸ ì¤‘ë³µ ì œê±°
        numClasses: 80
      };
      
      const predictions = await model.detect(processedImage, detectionConfig);
      
      console.log('ì›ì‹œ ì˜ˆì¸¡ ê²°ê³¼:', predictions);
      
      // ê²°ê³¼ í•„í„°ë§ ë° í´ë˜ìŠ¤ ë§¤í•‘
      const filteredPredictions = predictions
        .filter(pred => pred.score >= 0.4)
        .map(pred => enhanceObjectRecognition(pred));
      
      console.log('í–¥ìƒëœ ì˜ˆì¸¡ ê²°ê³¼:', filteredPredictions);
      
      setPredictions(filteredPredictions);
      
      // ìº”ë²„ìŠ¤ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
      drawBoundingBoxes(filteredPredictions);
      
      setStatus(`${filteredPredictions.length}ê°œì˜ ê°ì²´ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.`);
    } catch (error) {
      console.error('ê°ì²´ ê°ì§€ ì‹¤íŒ¨:', error);
      setStatus(`ê°ì²´ ê°ì§€ ì‹¤íŒ¨: ${error.message}`);
    } finally {
      setIsDetecting(false);
    }
  };

  // ê°ì²´ ì¸ì‹ í–¥ìƒ (í´ë˜ìŠ¤ ë§¤í•‘ ë° í™•ì¥)
  const enhanceObjectRecognition = (prediction) => {
    const { class: originalClass, score, bbox } = prediction;
    
    // í´ë˜ìŠ¤ ë§¤í•‘ ë° í™•ì¥
    const classMappings = {
      // ê°€êµ¬ ê´€ë ¨
      'chair': ['chair', 'stool', 'seat', 'í–‰ê±°', 'hanger'],
      'dining table': ['table', 'desk', 'dining table', 'ì±…ìƒ'],
      'bed': ['bed', 'mattress', 'ì¹¨ëŒ€'],
      
      // ìƒí™œìš©í’ˆ
      'scissors': ['scissors', 'ë¹¨ë˜ì§‘ê²Œ', 'clothespin', 'clip'],
      'handbag': ['bag', 'handbag', 'purse', 'ê°€ë°©'],
      'book': ['book', 'magazine', 'ì±…'],
      'bottle': ['bottle', 'container', 'ë³‘'],
      'cup': ['cup', 'mug', 'glass', 'ì»µ'],
      'bowl': ['bowl', 'dish', 'plate', 'ê·¸ë¦‡'],
      
      // ì˜ë¥˜ ê´€ë ¨
      'tie': ['tie', 'necktie', 'ë„¥íƒ€ì´'],
      'handbag': ['handbag', 'purse', 'bag', 'ì†ê°€ë°©'],
      
      // ì „ìì œí’ˆ
      'cell phone': ['phone', 'smartphone', 'cell phone', 'íœ´ëŒ€í°'],
      'laptop': ['laptop', 'computer', 'notebook', 'ë…¸íŠ¸ë¶'],
      'tv': ['tv', 'television', 'monitor', 'í…”ë ˆë¹„ì „'],
      
      // ê¸°íƒ€
      'clock': ['clock', 'watch', 'ì‹œê³„'],
      'vase': ['vase', 'pot', 'í™”ë¶„'],
      'teddy bear': ['toy', 'doll', 'teddy bear', 'ì¸í˜•']
    };
    
    // ì›ë³¸ í´ë˜ìŠ¤ê°€ ë§¤í•‘ì— ìˆìœ¼ë©´ í™•ì¥ëœ í´ë˜ìŠ¤ë“¤ ì¶”ê°€
    if (classMappings[originalClass]) {
      const enhancedClasses = classMappings[originalClass];
      // ê°€ì¥ ì ì ˆí•œ í´ë˜ìŠ¤ ì„ íƒ (ì²« ë²ˆì§¸ê°€ ê°€ì¥ ì¼ë°˜ì )
      const enhancedClass = enhancedClasses[0];
      
      return {
        ...prediction,
        class: enhancedClass,
        originalClass: originalClass,
        possibleClasses: enhancedClasses,
        confidence: score
      };
    }
    
    return {
      ...prediction,
      confidence: score
    };
  };

  // ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
  const preprocessImageForDetection = (imageElement) => {
    try {
      // ìµœì  í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì„±ëŠ¥ê³¼ ì •í™•ë„ì˜ ê· í˜•)
      const targetSize = 300;
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      
      if (!ctx) {
        console.error('Canvas contextë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        return imageElement;
      }
      
      canvas.width = targetSize;
      canvas.height = targetSize;
      
      // ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
      ctx.imageSmoothingEnabled = true;
      ctx.imageSmoothingQuality = 'high';
      ctx.drawImage(imageElement, 0, 0, targetSize, targetSize);
      
      return canvas;
    } catch (error) {
      console.error('ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      return imageElement;
    }
  };



  // ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ê¸°ë³¸ ì„¤ì •)
  const drawBoundingBoxes = (predictions) => {
    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    if (!ctx) return;

    // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    predictions.forEach((prediction, index) => {
      const [x, y, width, height] = prediction.bbox;
      const confidence = Math.round(prediction.score * 100);
      
      // ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
      ctx.strokeStyle = '#00ff00';
      ctx.lineWidth = 3;
      ctx.strokeRect(x, y, width, height);
      
      // ë¼ë²¨ ê·¸ë¦¬ê¸°
      ctx.fillStyle = '#00ff00';
      ctx.font = '16px Arial';
      ctx.fillText(`${prediction.class} (${confidence}%)`, x, y - 10);
      
      // í´ë¦­ ê°€ëŠ¥í•œ ì˜ì—­ í‘œì‹œë¥¼ ìœ„í•œ ì‚¬ê°í˜•
      ctx.strokeStyle = 'rgba(0, 255, 0, 0.3)';
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y - 25, ctx.measureText(`${prediction.class} (${confidence}%)`).width, 20);
    });
  };

  // ì‹ ë¢°ë„ì— ë”°ë¥¸ CSS í´ë˜ìŠ¤ ë°˜í™˜
  const getConfidenceClass = (score) => {
    if (score >= 0.8) return 'high';
    if (score >= 0.6) return 'medium';
    if (score >= 0.4) return 'low';
    return 'very-low';
  };

  // ì‹¤ì‹œê°„ ê°ì§€ í† ê¸€ (ì„±ëŠ¥ ìµœì í™”)
  const toggleRealTimeDetection = () => {
    if (!isRealTimeDetection) {
      setIsRealTimeDetection(true);
      setStatus('ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ìµœì í™” ëª¨ë“œ)');
      
      // 1.5ì´ˆë§ˆë‹¤ ê°ì²´ ê°ì§€ (ì„±ëŠ¥ê³¼ ë°˜ì‘ì„±ì˜ ê· í˜•)
      detectionIntervalRef.current = setInterval(() => {
        if (videoRef.current?.readyState === videoRef.current?.HAVE_ENOUGH_DATA) {
          // ì´ì „ ê°ì§€ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìŠ¤í‚µ
          if (!isDetecting) {
            detectObjects(videoRef.current);
          }
        }
      }, 1500);
    } else {
      setIsRealTimeDetection(false);
      setStatus('ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.');
      
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
        detectionIntervalRef.current = null;
      }
      
      // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
      const canvas = canvasRef.current;
      const ctx = canvas?.getContext('2d');
      if (ctx) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
      setPredictions([]);
    }
  };

  // ë‹¨ì–´ ì„ íƒ
  const handleWordSelect = (word) => {
    setSelectedWord(word);
  };

  // ë‹¨ì–´ì¥ì— ì¶”ê°€
  const addToVocabulary = (word) => {
    if (!vocabulary.find(item => item.word === word)) {
      const newItem = {
        word,
        addedAt: new Date().toISOString(),
        id: Date.now()
      };
      saveVocabulary([...vocabulary, newItem]);
    }
  };

  // ë‹¨ì–´ì¥ì—ì„œ ì œê±°
  const removeFromVocabulary = (id) => {
    const newVocabulary = vocabulary.filter(item => item.id !== id);
    saveVocabulary(newVocabulary);
  };

  // ìº”ë²„ìŠ¤ í´ë¦­ ì´ë²¤íŠ¸
  const handleCanvasClick = (event) => {
    if (predictions.length === 0) return;
    
    const canvas = canvasRef.current;
    const rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const y = event.clientY - rect.top;
    
    // í´ë¦­ëœ ê°ì²´ ì°¾ê¸°
    predictions.forEach(prediction => {
      const [bx, by, bwidth, bheight] = prediction.bbox;
      const labelHeight = 25;
      const labelY = by - labelHeight;
      
      // ë¼ë²¨ ì˜ì—­ í´ë¦­ í™•ì¸
      if (x >= bx && x <= bx + bwidth && y >= labelY && y <= by) {
        handleWordSelect(prediction.class);
      }
    });
  };

  return (
    <div className="container">
      <h1 className="header">ğŸ¯ English Learning with AI</h1>
      
      <div className="video-container">
        <video ref={videoRef} id="video" autoPlay muted playsInline></video>
        <canvas 
          ref={canvasRef} 
          id="canvas"
          onClick={handleCanvasClick}
          style={{ pointerEvents: 'auto' }}
        ></canvas>
      </div>

      <div className="controls">
        <button onClick={startCamera}>ğŸ“¹ Start Camera</button>
        <button 
          onClick={switchCamera}
          disabled={!videoRef.current?.srcObject}
          style={{
            background: 'linear-gradient(45deg, #9b59b6, #8e44ad)',
            opacity: videoRef.current?.srcObject ? 1 : 0.5
          }}
        >
          {isBackCamera ? 'ğŸ”„ ì „ë©´ ì¹´ë©”ë¼ë¡œ ì „í™˜' : 'ğŸ”„ í›„ë©´ ì¹´ë©”ë¼ë¡œ ì „í™˜'}
        </button>
        <button 
          onClick={() => setDetectionMode(detectionMode === 'normal' ? 'enhanced' : 'normal')}
          style={{
            background: detectionMode === 'enhanced' 
              ? 'linear-gradient(45deg, #00b894, #00a085)' 
              : 'linear-gradient(45deg, #fdcb6e, #e17055)'
          }}
        >
          {detectionMode === 'enhanced' ? 'ğŸ¯ í–¥ìƒ ëª¨ë“œ' : 'ğŸ” ì¼ë°˜ ëª¨ë“œ'}
        </button>
        <button 
          onClick={toggleRealTimeDetection}
          style={{
            background: isRealTimeDetection 
              ? 'linear-gradient(45deg, #ff6b6b, #ee5a24)' 
              : 'linear-gradient(45deg, #667eea, #764ba2)'
          }}
        >
          {isRealTimeDetection ? 'ğŸŸ¢ Stop Real-time Detection' : 'ğŸ”´ Start Real-time Detection'}
        </button>
        <button onClick={() => detectObjects(videoRef.current)}>ğŸ“¸ Capture & Detect</button>
        <button onClick={stopCamera}>â¹ï¸ Stop Camera</button>
      </div>

      <div className="status">{status}</div>
      
      {/* ë””ë²„ê¹… ì •ë³´ */}
      <div style={{ 
        background: '#f0f0f0', 
        padding: '10px', 
        margin: '10px 0', 
        borderRadius: '5px',
        fontSize: '12px',
        fontFamily: 'monospace'
      }}>
        <strong>ë””ë²„ê¹… ì •ë³´:</strong><br/>
        User Agent: {navigator.userAgent}<br/>
        TensorFlow ë°±ì—”ë“œ: {tf.getBackend()}<br/>
        ëª¨ë¸ ìƒíƒœ: {model ? 'ë¡œë“œë¨' : 'ë¡œë“œ ì•ˆë¨'}<br/>
        ê°ì§€ ëª¨ë“œ: {detectionMode === 'enhanced' ? 'í–¥ìƒ ëª¨ë“œ' : 'ì¼ë°˜ ëª¨ë“œ'}<br/>
        ê°ì§€ ì¤‘: {isDetecting ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}<br/>
        ì‹¤ì‹œê°„ ê°ì§€: {isRealTimeDetection ? 'í™œì„±' : 'ë¹„í™œì„±'}<br/>
        ì˜ˆì¸¡ ê²°ê³¼: {predictions.length}ê°œ<br/>
        ë¹„ë””ì˜¤ ìƒíƒœ: {videoRef.current?.readyState || 'ì—†ìŒ'}
      </div>

      {/* ì¸ì‹ íŒ */}
      <div style={{ 
        background: '#e8f4fd', 
        padding: '15px', 
        margin: '10px 0', 
        borderRadius: '10px',
        border: '2px solid #667eea'
      }}>
        <h4 style={{ margin: '0 0 10px 0', color: '#2c5aa0' }}>ğŸ’¡ ì¸ì‹ íŒ</h4>
        <p style={{ margin: '5px 0', fontSize: '14px' }}>
          <strong>ë¹¨ë˜ì§‘ê²Œ, ì†ìˆ˜ê±´, í–‰ê±°</strong> ê°™ì€ ì„¸ë¶€ ë¬¼ê±´ë“¤ì„ ì¸ì‹í•˜ë ¤ë©´:
        </p>
        <ul style={{ margin: '5px 0', paddingLeft: '20px', fontSize: '14px' }}>
          <li>ê°ì²´ë¥¼ í™”ë©´ ì¤‘ì•™ì— ë°°ì¹˜í•˜ì„¸ìš”</li>
          <li>ì¶©ë¶„í•œ ì¡°ëª…ì„ í™•ë³´í•˜ì„¸ìš”</li>
          <li>ê°ì²´ê°€ í™”ë©´ì˜ 1/4 ì´ìƒì„ ì°¨ì§€í•˜ë„ë¡ í•˜ì„¸ìš”</li>
          <li>ë°°ê²½ê³¼ êµ¬ë¶„ë˜ëŠ” ìƒ‰ìƒì˜ ë¬¼ê±´ì„ ì‚¬ìš©í•˜ì„¸ìš”</li>
          <li>ì—¬ëŸ¬ ê°ë„ì—ì„œ ì‹œë„í•´ë³´ì„¸ìš”</li>
        </ul>
        <p style={{ margin: '5px 0', fontSize: '12px', color: '#666' }}>
          í˜„ì¬ ëª¨ë¸ì€ 80ê°€ì§€ ì¼ë°˜ì ì¸ ê°ì²´ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤. 
          ì„¸ë¶€ ë¬¼ê±´ë“¤ì€ ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘ë©ë‹ˆë‹¤.
        </p>
      </div>

      <div className="detection-results">
        <h3>ğŸ” Detected Objects:</h3>
        {predictions.length === 0 ? (
          <div className="detection-item">ê°ì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.</div>
        ) : (
          predictions.map((prediction, index) => {
            const confidence = Math.round(prediction.score * 100);
            const confidenceClass = getConfidenceClass(prediction.score);
            
            return (
              <div key={index} className="detection-item">
                <span 
                  className="object-name" 
                  onClick={() => handleWordSelect(prediction.class)}
                >
                  {prediction.class}
                </span>
                <div>
                  <span className={`confidence ${confidenceClass}`}>
                    {confidence}%
                  </span>
                  <button 
                    className="save-button"
                    onClick={() => addToVocabulary(prediction.class)}
                    disabled={vocabulary.find(item => item.word === prediction.class)}
                  >
                    {vocabulary.find(item => item.word === prediction.class) ? 'âœ“ ì €ì¥ë¨' : 'ğŸ’¾ ì €ì¥'}
                  </button>
                </div>
              </div>
            );
          })
        )}
      </div>

      {selectedWord && (
        <WordDetail 
          word={selectedWord} 
          onClose={() => setSelectedWord(null)}
          onSave={() => addToVocabulary(selectedWord)}
          isSaved={vocabulary.find(item => item.word === selectedWord)}
        />
      )}

      <Vocabulary 
        vocabulary={vocabulary}
        onRemove={removeFromVocabulary}
        onWordSelect={handleWordSelect}
      />
    </div>
  );
}

export default App;